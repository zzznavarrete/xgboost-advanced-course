{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import (metrics, linear_model, preprocessing)\n",
    "from sklearn.model_selection import train_test_split \n",
    "import xgboost as xgb \n",
    "from matplotlib import pyplot\n",
    "# feature selection    make sure to update xgboost package\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from scipy.stats import uniform,randint\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path): \n",
    "    df = pd.read_csv(path, na_values='NA')\n",
    "    # Printing the dataswet shape \n",
    "    print (\"features:\") \n",
    "    print (list(df.columns)) \n",
    "    print (\"row and column number\") \n",
    "    print (df.shape) \n",
    "    print (\"data / feature types:\") \n",
    "    print (df.dtypes) \n",
    "    df_num = df.select_dtypes(include='number')\n",
    "    df_cat = df.select_dtypes(include='object')\n",
    "    print (\"missing values:\") \n",
    "    print (df.isnull().sum()) \n",
    "    return [df, df_num, df_cat] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:\n",
      "['ID', 'overdue', 'utilization', 'age', 'num30_59dayspastdue', 'debtratio', 'monthlyincome', 'numlinecredit', 'num90dayslate', 'nummortgate', 'num60_89dayspastdue', 'numdependents']\n",
      "row and column number\n",
      "(150000, 12)\n",
      "data / feature types:\n",
      "ID                       int64\n",
      "overdue                  int64\n",
      "utilization            float64\n",
      "age                      int64\n",
      "num30_59dayspastdue      int64\n",
      "debtratio              float64\n",
      "monthlyincome          float64\n",
      "numlinecredit            int64\n",
      "num90dayslate            int64\n",
      "nummortgate              int64\n",
      "num60_89dayspastdue      int64\n",
      "numdependents          float64\n",
      "dtype: object\n",
      "missing values:\n",
      "ID                         0\n",
      "overdue                    0\n",
      "utilization                0\n",
      "age                        0\n",
      "num30_59dayspastdue        0\n",
      "debtratio                  0\n",
      "monthlyincome          29731\n",
      "numlinecredit              0\n",
      "num90dayslate              0\n",
      "nummortgate                0\n",
      "num60_89dayspastdue        0\n",
      "numdependents           3924\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "path = '.\\..\\data\\creditscore.csv'\n",
    "dflist = read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard = dflist[0]\n",
    "predictor = list(scorecard.columns)\n",
    "\n",
    "\n",
    "# even though xgboost does not need missimg treatment, we still do that\n",
    "# since we need to analyze data patterns, such as correlation..\n",
    "scorecard['monthlyincome_miss']=pd.isnull(scorecard['monthlyincome'])+0 # Si le añado un 0 significa que el True/False se convierte en su equivalente binario 1/0\n",
    "scorecard['numdependents_miss']=pd.isnull(scorecard['numdependents'])+0\n",
    "# fill missing with mean value\n",
    "scorecard = scorecard.fillna(scorecard.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnamelist=list(scorecard.columns)\n",
    "varnamelist.remove('ID')\n",
    "varnamelist.remove('overdue')\n",
    "Y = scorecard.overdue\n",
    "Y.mean()\n",
    "Y.value_counts()\n",
    "\n",
    "corr=list()   # define an empty list\n",
    "# loop for all independent variables\n",
    "for vname in varnamelist: \n",
    "        X = scorecard[vname]              # loop all the variables in the data frame\n",
    "        C = np.corrcoef(X, Y)             # calculate correlation matrix\n",
    "        beta=np.round(C[1, 0],3)\n",
    "        corr=corr+[beta]                # gather all correlation coefficients in a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>correlation</th>\n",
       "      <th>abscorr</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num30_59dayspastdue</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num90dayslate</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.115</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num60_89dayspastdue</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.102</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>numdependents</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>numlinecredit</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>monthlyincome_miss</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monthlyincome</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>numdependents_miss</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debtratio</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nummortgate</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utilization</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                varname  correlation  abscorr  order\n",
       "2   num30_59dayspastdue        0.126    0.126      1\n",
       "6         num90dayslate        0.117    0.117      2\n",
       "1                   age       -0.115    0.115      3\n",
       "8   num60_89dayspastdue        0.102    0.102      4\n",
       "9         numdependents        0.046    0.046      5\n",
       "5         numlinecredit       -0.030    0.030      6\n",
       "10   monthlyincome_miss       -0.021    0.021      7\n",
       "4         monthlyincome       -0.018    0.018      8\n",
       "11   numdependents_miss       -0.014    0.014      9\n",
       "3             debtratio       -0.008    0.008     10\n",
       "7           nummortgate       -0.007    0.007     11\n",
       "0           utilization       -0.002    0.002     12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# change column names\n",
    "corrdf = pd.DataFrame({'varname': varnamelist, 'correlation': corr})\n",
    "corrdf['abscorr'] = np.abs(corrdf['correlation'])\n",
    "\n",
    "# sort absolute value of correlation in descending order\n",
    "corrdf.sort_values(['abscorr'], ascending=False, inplace=True)\n",
    "seq = range(1,len(corrdf)+1)\n",
    "corrdf['order']=seq  # add a sequential number column\n",
    "\n",
    "corrdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['utilization', 'age', 'num30_59dayspastdue', 'debtratio', 'monthlyincome', 'numlinecredit', 'num90dayslate', 'nummortgate', 'num60_89dayspastdue', 'numdependents', 'monthlyincome_miss', 'numdependents_miss', 'num30_59dayspastdue_0', 'num30_59dayspastdue_1', 'num30_59dayspastdue_2', 'num30_59dayspastdue_3', 'num30_59dayspastdue_4', 'num30_59dayspastdue_5', 'num30_59dayspastdue_6', 'num30_59dayspastdue_7', 'num30_59dayspastdue_8', 'num30_59dayspastdue_9', 'num30_59dayspastdue_10', 'num30_59dayspastdue_11', 'num30_59dayspastdue_12', 'num30_59dayspastdue_13', 'num30_59dayspastdue_96', 'num30_59dayspastdue_98', 'num90dayslate_0', 'num90dayslate_1', 'num90dayslate_2', 'num90dayslate_3', 'num90dayslate_4', 'num90dayslate_5', 'num90dayslate_6', 'num90dayslate_7', 'num90dayslate_8', 'num90dayslate_9', 'num90dayslate_10', 'num90dayslate_11', 'num90dayslate_12', 'num90dayslate_13', 'num90dayslate_14', 'num90dayslate_15', 'num90dayslate_17', 'num90dayslate_96', 'num90dayslate_98', 'num60_89dayspastdue_0', 'num60_89dayspastdue_1', 'num60_89dayspastdue_2', 'num60_89dayspastdue_3', 'num60_89dayspastdue_4', 'num60_89dayspastdue_5', 'num60_89dayspastdue_6', 'num60_89dayspastdue_7', 'num60_89dayspastdue_8', 'num60_89dayspastdue_9', 'num60_89dayspastdue_11', 'num60_89dayspastdue_96', 'num60_89dayspastdue_98']\n"
     ]
    }
   ],
   "source": [
    "# get one hot features for num30_59dayspastdue, num90dayslate and num60_89dayspastdue \n",
    "scorecard.num90dayslate.value_counts()\n",
    "\n",
    "names = ['num30_59dayspastdue', 'num90dayslate', 'num60_89dayspastdue']\n",
    "for it in names:\n",
    "    df_1 = pd.get_dummies(scorecard[it])\n",
    "    colnames = list(df_1.columns)\n",
    "    colnames_new = [it + \"_\" + str(colname) for colname in colnames]\n",
    "    df_1.columns = colnames_new\n",
    "    scorecard = pd.concat([scorecard, df_1], axis=1)\n",
    "\n",
    "list(scorecard.columns)\n",
    "\n",
    "predictor = list(scorecard.columns)\n",
    "\n",
    "for s in ['overdue', 'ID']:\n",
    "    predictor.remove(s)\n",
    "    \n",
    "print (predictor)\n",
    "\n",
    "X = scorecard[predictor]\n",
    "y = scorecard.overdue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.8567698536061586\n",
      "Accuracy: 93.64%\n",
      "Process finished --- 11.461010456085205 seconds ---\n",
      "ROC AUC 0.8615049600997617\n",
      "Accuracy: 93.70%\n",
      "Process finished --- 22.243997812271118 seconds ---\n",
      "ROC AUC 0.8623139225706689\n",
      "Accuracy: 93.46%\n",
      "Process finished --- 33.155399322509766 seconds ---\n",
      "ROC AUC 0.8573203914233312\n",
      "Accuracy: 93.66%\n",
      "Process finished --- 43.548136711120605 seconds ---\n",
      "ROC AUC 0.8546381002091002\n",
      "Accuracy: 93.64%\n",
      "Process finished --- 53.57620286941528 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Cross-validation\n",
    "NFOLDS = 5\n",
    "kf = KFold(n_splits = NFOLDS, shuffle = True)\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X, y):\n",
    "\n",
    "    clf = xgb.XGBClassifier(\n",
    "    learning_rate =0.03,\n",
    "    n_estimators = 1200,\n",
    "    max_depth = 7,\n",
    "    objective= 'binary:logistic',\n",
    "    min_child_weight=5, \n",
    "    gamma=0.05, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    seed = 12,\n",
    "    tree_method = 'hist'\n",
    "  )\n",
    "    \n",
    "    X_tr, X_vl = X.iloc[tr_idx, :], X.iloc[val_idx, :]\n",
    "    y_tr, y_vl = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "    \n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "    \n",
    "    y_pred_train0 = clf.predict(X_vl)\n",
    "    accuracy = accuracy_score(y_vl, y_pred_train0)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "    print(\"Process finished --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.857389216215282\n",
      "Accuracy: 93.62%\n",
      "Process finished --- 8.203361511230469 seconds ---\n",
      "ROC AUC 0.8614314700959277\n",
      "Accuracy: 93.60%\n",
      "Process finished --- 16.21073889732361 seconds ---\n",
      "ROC AUC 0.8558097468570025\n",
      "Accuracy: 93.44%\n",
      "Process finished --- 24.11885714530945 seconds ---\n",
      "ROC AUC 0.8608536165882742\n",
      "Accuracy: 93.66%\n",
      "Process finished --- 32.02174210548401 seconds ---\n",
      "ROC AUC 0.8591300215754338\n",
      "Accuracy: 93.74%\n",
      "Process finished --- 40.13109993934631 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Cross-validation\n",
    "NFOLDS = 5\n",
    "kf = KFold(n_splits = NFOLDS, shuffle = True)\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X, y):\n",
    "\n",
    "    clf = xgb.XGBClassifier(\n",
    "    learning_rate =0.03,\n",
    "    n_estimators = 1200,\n",
    "    max_depth = 7,\n",
    "    objective= 'binary:logistic',\n",
    "    min_child_weight=5, \n",
    "    gamma=0.05, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    seed = 12,\n",
    "    tree_method = 'gpu_hist'\n",
    "  )\n",
    "    \n",
    "    X_tr, X_vl = X.iloc[tr_idx, :], X.iloc[val_idx, :]\n",
    "    y_tr, y_vl = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "    \n",
    "    print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "    \n",
    "    y_pred_train0 = clf.predict(X_vl)\n",
    "    accuracy = accuracy_score(y_vl, y_pred_train0)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    print(\"Process finished --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using native booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-auc:0.84696\ttrain-auc:0.84722\n",
      "[20]\tvalid-auc:0.86153\ttrain-auc:0.86502\n",
      "[40]\tvalid-auc:0.86270\ttrain-auc:0.86724\n",
      "[60]\tvalid-auc:0.86315\ttrain-auc:0.86902\n",
      "[80]\tvalid-auc:0.86426\ttrain-auc:0.87128\n",
      "[100]\tvalid-auc:0.86529\ttrain-auc:0.87374\n",
      "[120]\tvalid-auc:0.86574\ttrain-auc:0.87639\n",
      "[140]\tvalid-auc:0.86625\ttrain-auc:0.87892\n",
      "[160]\tvalid-auc:0.86651\ttrain-auc:0.88116\n",
      "[180]\tvalid-auc:0.86656\ttrain-auc:0.88342\n",
      "[200]\tvalid-auc:0.86660\ttrain-auc:0.88543\n",
      "[220]\tvalid-auc:0.86692\ttrain-auc:0.88736\n",
      "[240]\tvalid-auc:0.86680\ttrain-auc:0.88893\n",
      "[260]\tvalid-auc:0.86671\ttrain-auc:0.89019\n",
      "[280]\tvalid-auc:0.86654\ttrain-auc:0.89136\n",
      "[300]\tvalid-auc:0.86642\ttrain-auc:0.89227\n",
      "[320]\tvalid-auc:0.86631\ttrain-auc:0.89349\n",
      "[340]\tvalid-auc:0.86623\ttrain-auc:0.89424\n",
      "[360]\tvalid-auc:0.86617\ttrain-auc:0.89512\n",
      "[380]\tvalid-auc:0.86601\ttrain-auc:0.89612\n",
      "[400]\tvalid-auc:0.86599\ttrain-auc:0.89710\n",
      "[420]\tvalid-auc:0.86594\ttrain-auc:0.89791\n",
      "[440]\tvalid-auc:0.86586\ttrain-auc:0.89869\n",
      "[460]\tvalid-auc:0.86579\ttrain-auc:0.89952\n",
      "[480]\tvalid-auc:0.86555\ttrain-auc:0.90044\n",
      "[500]\tvalid-auc:0.86553\ttrain-auc:0.90120\n",
      "[520]\tvalid-auc:0.86534\ttrain-auc:0.90220\n",
      "[540]\tvalid-auc:0.86522\ttrain-auc:0.90298\n",
      "[560]\tvalid-auc:0.86500\ttrain-auc:0.90360\n",
      "[580]\tvalid-auc:0.86478\ttrain-auc:0.90432\n",
      "[600]\tvalid-auc:0.86461\ttrain-auc:0.90500\n",
      "[620]\tvalid-auc:0.86441\ttrain-auc:0.90576\n",
      "[640]\tvalid-auc:0.86431\ttrain-auc:0.90644\n",
      "[660]\tvalid-auc:0.86412\ttrain-auc:0.90712\n",
      "[680]\tvalid-auc:0.86396\ttrain-auc:0.90785\n",
      "[700]\tvalid-auc:0.86374\ttrain-auc:0.90868\n",
      "[720]\tvalid-auc:0.86357\ttrain-auc:0.90925\n",
      "[740]\tvalid-auc:0.86346\ttrain-auc:0.90989\n",
      "[760]\tvalid-auc:0.86335\ttrain-auc:0.91050\n",
      "[780]\tvalid-auc:0.86321\ttrain-auc:0.91108\n",
      "[800]\tvalid-auc:0.86308\ttrain-auc:0.91163\n",
      "[820]\tvalid-auc:0.86286\ttrain-auc:0.91240\n",
      "[840]\tvalid-auc:0.86268\ttrain-auc:0.91308\n",
      "[860]\tvalid-auc:0.86251\ttrain-auc:0.91370\n",
      "[880]\tvalid-auc:0.86232\ttrain-auc:0.91433\n",
      "[900]\tvalid-auc:0.86222\ttrain-auc:0.91507\n",
      "[920]\tvalid-auc:0.86200\ttrain-auc:0.91574\n",
      "[940]\tvalid-auc:0.86187\ttrain-auc:0.91654\n",
      "[960]\tvalid-auc:0.86164\ttrain-auc:0.91720\n",
      "[980]\tvalid-auc:0.86145\ttrain-auc:0.91782\n",
      "[1000]\tvalid-auc:0.86135\ttrain-auc:0.91836\n",
      "[1020]\tvalid-auc:0.86119\ttrain-auc:0.91902\n",
      "[1040]\tvalid-auc:0.86099\ttrain-auc:0.91958\n",
      "[1060]\tvalid-auc:0.86084\ttrain-auc:0.91996\n",
      "[1080]\tvalid-auc:0.86070\ttrain-auc:0.92048\n",
      "[1100]\tvalid-auc:0.86060\ttrain-auc:0.92110\n",
      "[1120]\tvalid-auc:0.86046\ttrain-auc:0.92168\n",
      "[1140]\tvalid-auc:0.86027\ttrain-auc:0.92216\n",
      "[1160]\tvalid-auc:0.86020\ttrain-auc:0.92249\n",
      "[1180]\tvalid-auc:0.86000\ttrain-auc:0.92301\n",
      "[1199]\tvalid-auc:0.85982\ttrain-auc:0.92337\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( \n",
    "        X, y, test_size = 0.15, random_state = 122) \n",
    "\n",
    "\n",
    "params = {'learning_rate' : 0.03,\n",
    "    'max_depth' : 7,\n",
    "    'objective' : 'binary:logistic',\n",
    "    'min_child_weight' : 5, \n",
    "    'gamma' : 0.05, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed' : 12,\n",
    "    'eval_metric' : 'auc',\n",
    "    'tree_method' : 'gpu_hist',\n",
    "    'sampling_method': 'gradient_based'\n",
    "}\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train.values,\n",
    "                    feature_names=X_train.columns,\n",
    "                    label=y_train.values)\n",
    "\n",
    "dvalid = xgb.DMatrix(data=X_valid.values,\n",
    "                    feature_names=X_valid.columns,\n",
    "                    label=y_valid.values)\n",
    "\n",
    "mod = xgb.train(params=params,\n",
    "                dtrain=dtrain,\n",
    "                num_boost_round = 1200, # Número máximo de iteraciones que el algoritmo va a correr\n",
    "                early_stopping_rounds=50, # Número de rondas hacia el futuro de la que ve hasta el momento para determinar si parar el entrenamiento o no\n",
    "                evals=[(dvalid,'valid'), (dtrain,'train')],\n",
    "                verbose_eval=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando 'cv' para cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.05, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=216, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.05, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=216, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.05, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=216, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( \n",
    "        X, y, test_size = 0.27, random_state = 122) \n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train.values,\n",
    "                    feature_names=X_train.columns,\n",
    "                    label=y_train.values)\n",
    "\n",
    "dvalid = xgb.DMatrix(data=X_valid.values,\n",
    "                    feature_names=X_valid.columns,\n",
    "                    label=y_valid.values)\n",
    "\n",
    "xgb_params = {'learning_rate' : 0.03,\n",
    "    'max_depth' : 7,\n",
    "    'objective' : 'binary:logistic',\n",
    "    'min_child_weight' : 5, \n",
    "    'gamma' : 0.05, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed' : 12\n",
    "}\n",
    "\n",
    "eval_cv = xgb.cv(xgb_params, dtrain, num_boost_round=1200, nfold = 5,\n",
    "            metrics='auc', early_stopping_rounds=80)\n",
    "        \n",
    "clf = xgb.XGBClassifier(\n",
    "    learning_rate =0.03,\n",
    "    n_estimators = 1200,\n",
    "    max_depth = 7,\n",
    "    objective= 'binary:logistic',\n",
    "    min_child_weight=5, \n",
    "    gamma=0.05, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    seed = 12,\n",
    "    tree_method='gpu_hist',\n",
    "    sampling_method='gradient_based')\n",
    "    \n",
    "    \n",
    "clf.set_params(n_estimators = eval_cv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\udemy\\xgboost\\xgboost_env\\Lib\\site-packages\\xgboost\\sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.8654487321857303\n"
     ]
    }
   ],
   "source": [
    "clf.set_params(n_estimators = eval_cv.shape[0])\n",
    "        \n",
    "clf.fit(X_train, y_train, eval_metric='auc', verbose=True)\n",
    "        \n",
    "predictions_prob = clf.predict_proba(X_valid)[:,1]      \n",
    "    \n",
    "print('ROC AUC {}'.format(roc_auc_score(y_valid, predictions_prob)))\n",
    "\n",
    "\n",
    "#  we use the following ways\n",
    "imp_gain = clf.get_booster().get_score(importance_type=\"gain\")\n",
    "imp_weight = clf.get_booster().get_score(importance_type=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utilization': 26.86141586303711, 'age': 5.045316696166992, 'num30_59dayspastdue': 34.05958938598633, 'debtratio': 4.193957805633545, 'monthlyincome': 3.8325703144073486, 'numlinecredit': 4.916317939758301, 'num90dayslate': 115.24346160888672, 'nummortgate': 6.071907997131348, 'num60_89dayspastdue': 19.200992584228516, 'numdependents': 3.367438316345215, 'monthlyincome_miss': 4.214170932769775, 'numdependents_miss': 2.8333280086517334, 'num30_59dayspastdue_0': 40.428749084472656, 'num30_59dayspastdue_1': 5.541392803192139, 'num30_59dayspastdue_2': 4.4015116691589355, 'num30_59dayspastdue_3': 3.854369878768921, 'num30_59dayspastdue_4': 3.5719306468963623, 'num30_59dayspastdue_5': 4.550775527954102, 'num30_59dayspastdue_6': 3.0224950313568115, 'num30_59dayspastdue_98': 0.5659983158111572, 'num90dayslate_0': 131.66262817382812, 'num90dayslate_1': 12.234856605529785, 'num90dayslate_2': 12.029308319091797, 'num90dayslate_3': 12.055765151977539, 'num90dayslate_4': 5.5554070472717285, 'num90dayslate_6': 2.101341724395752, 'num60_89dayspastdue_0': 15.683757781982422, 'num60_89dayspastdue_1': 5.239841938018799, 'num60_89dayspastdue_2': 6.486581802368164, 'num60_89dayspastdue_3': 4.689064025878906, 'num60_89dayspastdue_4': 1.775880217552185}\n",
      "{'utilization': 2853.0, 'age': 2636.0, 'num30_59dayspastdue': 867.0, 'debtratio': 3588.0, 'monthlyincome': 2576.0, 'numlinecredit': 1933.0, 'num90dayslate': 577.0, 'nummortgate': 949.0, 'num60_89dayspastdue': 821.0, 'numdependents': 706.0, 'monthlyincome_miss': 74.0, 'numdependents_miss': 22.0, 'num30_59dayspastdue_0': 107.0, 'num30_59dayspastdue_1': 101.0, 'num30_59dayspastdue_2': 81.0, 'num30_59dayspastdue_3': 29.0, 'num30_59dayspastdue_4': 42.0, 'num30_59dayspastdue_5': 4.0, 'num30_59dayspastdue_6': 14.0, 'num30_59dayspastdue_98': 1.0, 'num90dayslate_0': 97.0, 'num90dayslate_1': 58.0, 'num90dayslate_2': 35.0, 'num90dayslate_3': 17.0, 'num90dayslate_4': 20.0, 'num90dayslate_6': 5.0, 'num60_89dayspastdue_0': 150.0, 'num60_89dayspastdue_1': 100.0, 'num60_89dayspastdue_2': 63.0, 'num60_89dayspastdue_3': 47.0, 'num60_89dayspastdue_4': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(imp_gain)\n",
    "print(imp_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
